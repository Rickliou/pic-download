#!/usr/bin/env python3
"""
18comic åœ–ç‰‡æŠ“å–èˆ‡é‚„åŸå·¥å…·

ç”¨æ³•ï¼š
    python main.py <URL> [--output-dir OUTPUT_DIR] [--headless/--no-headless]

ç¯„ä¾‹ï¼š
    python main.py https://18comic.vip/photo/1223474 --output-dir ./output
"""
import argparse
import sys
import time
import random
from pathlib import Path

from descrambler import restore_image
from scraper import scrape_album, download_image


def main():
    """ä¸»ç¨‹å¼å…¥å£"""
    parser = argparse.ArgumentParser(
        description="18comic åœ–ç‰‡æŠ“å–èˆ‡é‚„åŸå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    parser.add_argument(
        "url",
        help="ç›¸ç°¿é é¢ URLï¼ˆå¦‚ https://18comic.vip/photo/1223474ï¼‰",
    )
    parser.add_argument(
        "--output-dir", "-o",
        default="./output",
        help="è¼¸å‡ºç›®éŒ„ï¼ˆé è¨­ï¼š./outputï¼‰",
    )
    parser.add_argument(
        "--headless/--no-headless",
        dest="headless",
        action=argparse.BooleanOptionalAction,
        default=True,
        help="æ˜¯å¦ä½¿ç”¨ç„¡é ­ç€è¦½å™¨æ¨¡å¼ï¼ˆé è¨­ï¼šæ˜¯ï¼‰",
    )
    parser.add_argument(
        "--delay",
        type=float,
        default=0.5,
        help="æ¯å¼µåœ–ç‰‡ä¸‹è¼‰é–“éš”ç§’æ•¸ï¼ˆé è¨­ï¼š0.5ï¼‰",
    )
    
    args = parser.parse_args()
    
    # å»ºç«‹è¼¸å‡ºç›®éŒ„
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ” æ­£åœ¨è§£æé é¢: {args.url}")
    
    try:
        # çˆ¬å–ç›¸ç°¿è³‡è¨Š
        album = scrape_album(args.url, headless=args.headless)
        print(f"ğŸ“š ç›¸ç°¿æ¨™é¡Œ: {album.title}")
        print(f"ğŸ†” ç›¸ç°¿ ID: {album.aid}")
        print(f"ğŸ–¼ï¸  å…±æ‰¾åˆ° {len(album.images)} å¼µåœ–ç‰‡")
        
        if not album.images:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•åœ–ç‰‡")
            sys.exit(1)
        
        # å»ºç«‹ä»¥ aid å‘½åçš„å­ç›®éŒ„
        album_dir = output_dir / str(album.aid)
        album_dir.mkdir(exist_ok=True)
        
        # ä¸‹è¼‰ä¸¦é‚„åŸæ¯å¼µåœ–ç‰‡
        for img_info in album.images:
            # è¼¸å‡ºæª”åï¼šæŒ‰é †åºç·¨è™Ÿ + åŸå§‹ photo_id
            output_filename = f"{img_info.index:04d}_{img_info.photo_id}.webp"
            output_path = album_dir / output_filename
            
            # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if output_path.exists():
                print(f"  â­ï¸  [{img_info.index}/{len(album.images)}] å·²å­˜åœ¨ï¼Œè·³é")
                continue
            
            print(f"  ğŸ“¥ [{img_info.index}/{len(album.images)}] ä¸‹è¼‰ä¸­: {img_info.photo_id}...", end=" ")
            
            try:
                # ä¸‹è¼‰åœ–ç‰‡
                scrambled_data = download_image(img_info.url, referer=args.url)
                
                # é‚„åŸåœ–ç‰‡
                restored_img = restore_image(scrambled_data, album.aid, img_info.photo_id)
                
                # å„²å­˜
                restored_img.save(output_path)
                print(f"âœ… å®Œæˆ")
                
            except Exception as e:
                print(f"âŒ å¤±æ•—: {e}")
                continue
            
            # éš¨æ©Ÿå»¶é²ï¼Œé¿å…è«‹æ±‚éæ–¼é »ç¹
            delay = args.delay + random.uniform(0, 0.3)
            time.sleep(delay)
        
        print(f"\nğŸ‰ å®Œæˆï¼åœ–ç‰‡å·²å„²å­˜è‡³: {album_dir.absolute()}")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ä½¿ç”¨è€…ä¸­æ–·")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ éŒ¯èª¤: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
